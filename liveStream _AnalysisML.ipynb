{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "from tweepy import API \n",
    "from tweepy import Cursor\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "consumer_token = \"RSV1mfohvaB3k3heHogWLJo7A\"\n",
    "consumer_secret = \"ZPwMBhBtm5A1hd1O1KSwRKc9Pzd29Xz93H7Kzsz0xoGmXlFQ1X\"\n",
    "access_token = \"938003970454306817-lV6LNuAYReogSr9wqy3yr9cUklphFtB\"\n",
    "access_secret = \"iUgF09ZT1kzXEpESJagRfYXmeqkuXvazfWIBCLRaRGySG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # # # TWITTER CLIENT # # # #\n",
    "class TwitterClient():\n",
    "    def __init__(self, twitter_user=None):\n",
    "        self.auth = TwitterAuthenticator().authenticate_twitter_app()\n",
    "        self.twitter_client = API(self.auth)\n",
    "\n",
    "        self.twitter_user = twitter_user\n",
    "\n",
    "    def get_user_timeline_tweets(self, num_tweets):\n",
    "        tweets = []\n",
    "        for tweet in Cursor(self.twitter_client.user_timeline, id=self.twitter_user).items(num_tweets):\n",
    "            tweets.append(tweet)\n",
    "        return tweets\n",
    "    \n",
    "    def get_twitter_client_api(self):\n",
    "        return self.twitter_client\n",
    "\n",
    "    def get_friend_list(self, num_friends):\n",
    "        friend_list = []\n",
    "        for friend in Cursor(self.twitter_client.friends, id=self.twitter_user).items(num_friends):\n",
    "            friend_list.append(friend)\n",
    "        return friend_list\n",
    "\n",
    "    def get_home_timeline_tweets(self, num_tweets):\n",
    "        home_timeline_tweets = []\n",
    "        for tweet in Cursor(self.twitter_client.home_timeline, id=self.twitter_user).items(num_tweets):\n",
    "            home_timeline_tweets.append(tweet)\n",
    "        return home_timeline_tweets\n",
    "\n",
    "\n",
    "# # # # TWITTER AUTHENTICATER # # # #\n",
    "class TwitterAuthenticator():\n",
    "\n",
    "    def authenticate_twitter_app(self):\n",
    "        auth = OAuthHandler(consumer_token, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_secret)\n",
    "        return auth\n",
    "\n",
    "# # # # TWITTER STREAMER # # # #\n",
    "class TwitterStreamer():\n",
    "    \"\"\"\n",
    "    Class for streaming and processing live tweets.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.twitter_autenticator = TwitterAuthenticator()    \n",
    "\n",
    "    def stream_tweets(self, fetched_tweets_filename, hash_tag_list):\n",
    "        # This handles Twitter authetification and the connection to Twitter Streaming API\n",
    "        listener = TwitterListener(fetched_tweets_filename)\n",
    "        auth = self.twitter_autenticator.authenticate_twitter_app() \n",
    "        stream = Stream(auth, listener)\n",
    "\n",
    "        # This line filter Twitter Streams to capture data by the keywords: \n",
    "        stream.filter(track=hash_tag_list)\n",
    "\n",
    "\n",
    "# # # # TWITTER STREAM LISTENER # # # #\n",
    "class TwitterListener(StreamListener):\n",
    "    \"\"\"\n",
    "    This is a basic listener that just prints received tweets to stdout.\n",
    "    \"\"\"\n",
    "    def __init__(self, fetched_tweets_filename):\n",
    "        self.fetched_tweets_filename = fetched_tweets_filename\n",
    "\n",
    "    def on_data(self, data):\n",
    "        try:\n",
    "            print(data)\n",
    "            with open(self.fetched_tweets_filename, 'a') as tf:\n",
    "                tf.write(data)\n",
    "            return True\n",
    "        except BaseException as e:\n",
    "            print(\"Error on_data %s\" % str(e))\n",
    "        return True\n",
    "          \n",
    "    def on_error(self, status):\n",
    "        if status == 420:\n",
    "            # Returning False on_data method in case rate limit occurs.\n",
    "            return False\n",
    "        print(status)\n",
    "        \n",
    "class TweetAnalyzer():\n",
    "    \"\"\"\n",
    "    Functionality for analyzing and categorizing content from tweets.\n",
    "    \"\"\"\n",
    "\n",
    "    def clean_tweet(self, tweet):\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "    def analyze_sentiment(self, tweet):\n",
    "        analysis = TextBlob(self.clean_tweet(tweet))\n",
    "        \n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 1\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 0.5\n",
    "        else:\n",
    "            return 0\n",
    "#         return analysis.sentiment.polarity\n",
    "\n",
    "    def tweets_to_data_frame(self, tweets):\n",
    "        df = pd.DataFrame(data=[tweet.text for tweet in tweets], columns=['tweets'])\n",
    "\n",
    "        df['id'] = np.array([tweet.id for tweet in tweets])\n",
    "        df['len'] = np.array([len(tweet.text) for tweet in tweets])\n",
    "        df['date'] = np.array([tweet.created_at for tweet in tweets])\n",
    "        df['source'] = np.array([tweet.source for tweet in tweets])\n",
    "        df['likes'] = np.array([tweet.favorite_count for tweet in tweets])\n",
    "        df['retweets'] = np.array([tweet.retweet_count for tweet in tweets])\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           tweets                   id  len  \\\n",
      "0                it was a very bad terrible movie  1192337605053927425   32   \n",
      "1  Harry Potter is a very good movie. I liked it.  1192336563553755136   46   \n",
      "2                            I do not like keshav  1185503328416829441   20   \n",
      "3                           i liked the new movie  1185503258560716800   21   \n",
      "4                                 hello like good  1185421084901826561   15   \n",
      "\n",
      "                 date           source  likes  retweets  sentiment  \n",
      "0 2019-11-07 07:06:52  Twitter Web App      0         0        0.0  \n",
      "1 2019-11-07 07:02:43  Twitter Web App      0         0        1.0  \n",
      "2 2019-10-19 10:29:53  Twitter Web App      0         0        0.5  \n",
      "3 2019-10-19 10:29:37  Twitter Web App      0         0        1.0  \n",
      "4 2019-10-19 05:03:05  Twitter Web App      0         0        1.0  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    twitter_client = TwitterClient()\n",
    "    tweet_analyzer = TweetAnalyzer()\n",
    "\n",
    "    api = twitter_client.get_twitter_client_api()\n",
    "\n",
    "    tweets = api.user_timeline(screen_name=\"SatvikNema4\", count=20)\n",
    "\n",
    "    df = tweet_analyzer.tweets_to_data_frame(tweets)\n",
    "    df['sentiment'] = np.array([tweet_analyzer.analyze_sentiment(tweet) for tweet in df['tweets']])\n",
    "\n",
    "    print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "for i in tweets:\n",
    "    temp = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", i.text).split()).lower() \n",
    "    final.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it was a very bad terrible movie',\n",
       " 'harry potter is a very good movie i liked it',\n",
       " 'i do not like keshav',\n",
       " 'i liked the new movie',\n",
       " 'hello like good']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.backend import tensorflow_backend as K\n",
    "from keras.datasets import imdb\n",
    "model = tf.keras.models.load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# The first indices are reserved\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # unknown\n",
    "word_index[\"<UNUSED>\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it', 'was', 'a', 'very', 'bad', 'terrible', 'movie']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final[0].split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it  is present in the dictionary\n",
      "was  is present in the dictionary\n",
      "a  is present in the dictionary\n",
      "very  is present in the dictionary\n",
      "bad  is present in the dictionary\n",
      "terrible  is present in the dictionary\n",
      "movie  is present in the dictionary\n",
      "harry  is present in the dictionary\n",
      "potter  is present in the dictionary\n",
      "is  is present in the dictionary\n",
      "a  is present in the dictionary\n",
      "very  is present in the dictionary\n",
      "good  is present in the dictionary\n",
      "movie  is present in the dictionary\n",
      "i  is present in the dictionary\n",
      "liked  is present in the dictionary\n",
      "it  is present in the dictionary\n",
      "i  is present in the dictionary\n",
      "do  is present in the dictionary\n",
      "not  is present in the dictionary\n",
      "like  is present in the dictionary\n",
      "i  is present in the dictionary\n",
      "liked  is present in the dictionary\n",
      "the  is present in the dictionary\n",
      "new  is present in the dictionary\n",
      "movie  is present in the dictionary\n",
      "hello  is present in the dictionary\n",
      "like  is present in the dictionary\n",
      "good  is present in the dictionary\n",
      "it\n",
      "was\n",
      "a\n",
      "very\n",
      "bad\n",
      "terrible\n",
      "movie\n",
      "harry\n",
      "potter\n",
      "is\n",
      "a\n",
      "very\n",
      "good\n",
      "movie\n",
      "i\n",
      "liked\n",
      "it\n",
      "i\n",
      "do\n",
      "not\n",
      "like\n",
      "i\n",
      "liked\n",
      "the\n",
      "new\n",
      "movie\n",
      "hello\n",
      "like\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "toModel = []\n",
    "x = []\n",
    "for i in final:\n",
    "    x=[]\n",
    "    words = i.split(\" \")\n",
    "    for j in words:\n",
    "        if j in word_index.keys():\n",
    "            x.append(j)\n",
    "            print(j,\" is present in the dictionary\")\n",
    "    toModel.append(x)\n",
    "test = \"i loved loved good like awesome\"\n",
    "test = test.lower().split(\" \")\n",
    "data = []\n",
    "\n",
    "for tweet in toModel:\n",
    "    x=[]\n",
    "    for i in range(len(tweet)):\n",
    "        print(tweet[i])\n",
    "        t = word_index[tweet[i]]\n",
    "        x.append(t)\n",
    "    data.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79189"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index[\"rt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12, 16, 6, 55, 78, 394, 20],\n",
       " [1335, 6507, 9, 6, 55, 52, 20, 13, 423, 12],\n",
       " [13, 81, 24, 40],\n",
       " [13, 423, 4, 162, 20],\n",
       " [4825, 40, 52]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    length = len(data[i]) \n",
    "    while length<256:\n",
    "        data[i].append(0)\n",
    "        length+=1\n",
    "data = np.array(data)\n",
    "for i in range(len(data)):\n",
    "    print(len(data[i]))\n",
    "    data[i] = np.array(data[i])\n",
    "    data[i] = data[i].reshape(1,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "(5, 256)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n"
     ]
    }
   ],
   "source": [
    "print(type(data))\n",
    "for i in data:\n",
    "    print(type(i))\n",
    "print()\n",
    "print(data.shape)\n",
    "for i in data:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 256)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPrediction = model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['harry potter was a very good movie i liked it',\n",
       " 'i do not like keshav',\n",
       " 'i liked the new movie',\n",
       " 'kartik is bad',\n",
       " 'hello like good']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[\"Model\\'s output\"] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e55700d293f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tweets\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sentiment\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Model's output\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2932\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2933\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[1;32m-> 2934\u001b[1;33m                                                    raise_missing=True)\n\u001b[0m\u001b[0;32m   2935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[0;32m   1353\u001b[0m                           raise_missing}\n\u001b[1;32m-> 1354\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1355\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[0;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[0;32m   1162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1250\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'loc'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1252\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} not in index\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m             \u001b[1;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '[\"Model\\'s output\"] not in index'"
     ]
    }
   ],
   "source": [
    "df[[\"tweets\", \"sentiment\", \"Model's output\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Model's output\"] = modelPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8713924]\n",
      "[0.5010104]\n",
      "[0.74521655]\n",
      "[0.41664243]\n",
      "[0.73302317]\n"
     ]
    }
   ],
   "source": [
    "for i in modelPrediction:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>id</th>\n",
       "      <th>len</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Model's output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it was a very bad terrible movie</td>\n",
       "      <td>1192337605053927425</td>\n",
       "      <td>32</td>\n",
       "      <td>2019-11-07 07:06:52</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter is a very good movie. I liked it.</td>\n",
       "      <td>1192336563553755136</td>\n",
       "      <td>46</td>\n",
       "      <td>2019-11-07 07:02:43</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.884567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I do not like keshav</td>\n",
       "      <td>1185503328416829441</td>\n",
       "      <td>20</td>\n",
       "      <td>2019-10-19 10:29:53</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.501010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i liked the new movie</td>\n",
       "      <td>1185503258560716800</td>\n",
       "      <td>21</td>\n",
       "      <td>2019-10-19 10:29:37</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hello like good</td>\n",
       "      <td>1185421084901826561</td>\n",
       "      <td>15</td>\n",
       "      <td>2019-10-19 05:03:05</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.733023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           tweets                   id  len  \\\n",
       "0                it was a very bad terrible movie  1192337605053927425   32   \n",
       "1  Harry Potter is a very good movie. I liked it.  1192336563553755136   46   \n",
       "2                            I do not like keshav  1185503328416829441   20   \n",
       "3                           i liked the new movie  1185503258560716800   21   \n",
       "4                                 hello like good  1185421084901826561   15   \n",
       "\n",
       "                 date           source  likes  retweets  sentiment  \\\n",
       "0 2019-11-07 07:06:52  Twitter Web App      0         0        0.0   \n",
       "1 2019-11-07 07:02:43  Twitter Web App      0         0        1.0   \n",
       "2 2019-10-19 10:29:53  Twitter Web App      0         0        0.5   \n",
       "3 2019-10-19 10:29:37  Twitter Web App      0         0        1.0   \n",
       "4 2019-10-19 05:03:05  Twitter Web App      0         0        1.0   \n",
       "\n",
       "   Model's output  \n",
       "0        0.261429  \n",
       "1        0.884567  \n",
       "2        0.501010  \n",
       "3        0.745217  \n",
       "4        0.733023  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
