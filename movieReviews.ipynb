{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from keras.backend import tensorflow_backend as K\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_load_old = np.load\n",
    "\n",
    "# Using a pickled file instead, because the imdb dataset, if imported using the normal keras's methods, fails to load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "# load a chunk of the dataset\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "\n",
    "# Not compulsory to use - restore np.load for future normal usage\n",
    "np.load = np_load_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "#Example of how the raw data is fed into the Neural Network (offcourse the preprocessing is left out)\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary mapping words to an integer index. It has around 99,000 eneteries which represents each word in the dictionary\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# For some unique characters and types, the first 4 indexes and shifted accordingly\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  \n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "#vocabulary count used for the movie reviews (10,000 words), for each review\n",
    "vocab_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a funciton to convert the numericals (as above shown) to the correspinding the review in english\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is cell was ran after doing the preprocessing. If you execute this before it, you wont get the oadded zeros padding on the left\n",
    "test_data[0]\n",
    "\n",
    "# Directly taken from the tensorflow.org, for pre-processing\n",
    "#Padding 0s to the right of each input, making sure it is 256 digits long.\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data, value=word_index[\"<PAD>\"],padding='post', maxlen=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,289\n",
      "Trainable params: 160,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Doing the same padding for the testing data too\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data,value=word_index[\"<PAD>\"],padding='post',maxlen=256)\n",
    "\n",
    "#Making the model as defined in tensorflow.org---\n",
    "#Description is given in the report\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "#Compiling the model using binary cross entropy (as always used in classification problems)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.6916 - acc: 0.6143 - val_loss: 0.6892 - val_acc: 0.6841\n",
      "Epoch 2/50\n",
      "15000/15000 [==============================] - 1s 86us/sample - loss: 0.6842 - acc: 0.7203 - val_loss: 0.6785 - val_acc: 0.7256\n",
      "Epoch 3/50\n",
      "15000/15000 [==============================] - 1s 76us/sample - loss: 0.6679 - acc: 0.7617 - val_loss: 0.6580 - val_acc: 0.7514\n",
      "Epoch 4/50\n",
      "15000/15000 [==============================] - 1s 84us/sample - loss: 0.6394 - acc: 0.7741 - val_loss: 0.6259 - val_acc: 0.7747\n",
      "Epoch 5/50\n",
      "15000/15000 [==============================] - 1s 77us/sample - loss: 0.5985 - acc: 0.7952 - val_loss: 0.5852 - val_acc: 0.7931\n",
      "Epoch 6/50\n",
      "15000/15000 [==============================] - 1s 78us/sample - loss: 0.5496 - acc: 0.8211 - val_loss: 0.5396 - val_acc: 0.8115\n",
      "Epoch 7/50\n",
      "15000/15000 [==============================] - 1s 77us/sample - loss: 0.4986 - acc: 0.8377 - val_loss: 0.4922 - val_acc: 0.8281\n",
      "Epoch 8/50\n",
      "15000/15000 [==============================] - 1s 77us/sample - loss: 0.4495 - acc: 0.8569 - val_loss: 0.4510 - val_acc: 0.8417\n",
      "Epoch 9/50\n",
      "15000/15000 [==============================] - 1s 77us/sample - loss: 0.4063 - acc: 0.8705 - val_loss: 0.4166 - val_acc: 0.8504\n",
      "Epoch 10/50\n",
      "15000/15000 [==============================] - 1s 86us/sample - loss: 0.3702 - acc: 0.8805 - val_loss: 0.3888 - val_acc: 0.8560\n",
      "Epoch 11/50\n",
      "15000/15000 [==============================] - 1s 94us/sample - loss: 0.3404 - acc: 0.8866 - val_loss: 0.3672 - val_acc: 0.8635\n",
      "Epoch 12/50\n",
      "15000/15000 [==============================] - 1s 87us/sample - loss: 0.3148 - acc: 0.8945 - val_loss: 0.3501 - val_acc: 0.8670\n",
      "Epoch 13/50\n",
      "15000/15000 [==============================] - 1s 86us/sample - loss: 0.2936 - acc: 0.9001 - val_loss: 0.3361 - val_acc: 0.8717\n",
      "Epoch 14/50\n",
      "15000/15000 [==============================] - 1s 76us/sample - loss: 0.2745 - acc: 0.9061 - val_loss: 0.3250 - val_acc: 0.8742\n",
      "Epoch 15/50\n",
      "15000/15000 [==============================] - 1s 76us/sample - loss: 0.2584 - acc: 0.9109 - val_loss: 0.3178 - val_acc: 0.8737\n",
      "Epoch 16/50\n",
      "15000/15000 [==============================] - 1s 77us/sample - loss: 0.2443 - acc: 0.9155 - val_loss: 0.3090 - val_acc: 0.8778\n",
      "Epoch 17/50\n",
      "15000/15000 [==============================] - 1s 77us/sample - loss: 0.2323 - acc: 0.9191 - val_loss: 0.3043 - val_acc: 0.8795\n",
      "Epoch 18/50\n",
      "15000/15000 [==============================] - 1s 77us/sample - loss: 0.2196 - acc: 0.9243 - val_loss: 0.2979 - val_acc: 0.8821\n",
      "Epoch 19/50\n",
      "15000/15000 [==============================] - 1s 77us/sample - loss: 0.2083 - acc: 0.9295 - val_loss: 0.2944 - val_acc: 0.8820\n",
      "Epoch 20/50\n",
      "15000/15000 [==============================] - 1s 78us/sample - loss: 0.1983 - acc: 0.9329 - val_loss: 0.2926 - val_acc: 0.8825\n",
      "Epoch 21/50\n",
      "15000/15000 [==============================] - 1s 77us/sample - loss: 0.1892 - acc: 0.9369 - val_loss: 0.2888 - val_acc: 0.8847\n",
      "Epoch 22/50\n",
      "15000/15000 [==============================] - 1s 92us/sample - loss: 0.1804 - acc: 0.9415 - val_loss: 0.2872 - val_acc: 0.8846\n",
      "Epoch 23/50\n",
      "15000/15000 [==============================] - 1s 90us/sample - loss: 0.1722 - acc: 0.9453 - val_loss: 0.2865 - val_acc: 0.8850\n",
      "Epoch 24/50\n",
      "15000/15000 [==============================] - 1s 77us/sample - loss: 0.1647 - acc: 0.9481 - val_loss: 0.2856 - val_acc: 0.8848\n",
      "Epoch 25/50\n",
      "15000/15000 [==============================] - 1s 92us/sample - loss: 0.1582 - acc: 0.9516 - val_loss: 0.2853 - val_acc: 0.8855\n",
      "Epoch 26/50\n",
      "15000/15000 [==============================] - 1s 82us/sample - loss: 0.1511 - acc: 0.9537 - val_loss: 0.2855 - val_acc: 0.8859\n",
      "Epoch 27/50\n",
      "15000/15000 [==============================] - 1s 91us/sample - loss: 0.1443 - acc: 0.9569 - val_loss: 0.2873 - val_acc: 0.8851\n",
      "Epoch 28/50\n",
      "15000/15000 [==============================] - 1s 90us/sample - loss: 0.1385 - acc: 0.9589 - val_loss: 0.2875 - val_acc: 0.8867\n",
      "Epoch 29/50\n",
      "15000/15000 [==============================] - 1s 89us/sample - loss: 0.1331 - acc: 0.9611 - val_loss: 0.2903 - val_acc: 0.8848\n",
      "Epoch 30/50\n",
      "15000/15000 [==============================] - 1s 77us/sample - loss: 0.1276 - acc: 0.9629 - val_loss: 0.2907 - val_acc: 0.8855\n",
      "Epoch 31/50\n",
      "15000/15000 [==============================] - 1s 81us/sample - loss: 0.1220 - acc: 0.9657 - val_loss: 0.2921 - val_acc: 0.8855\n",
      "Epoch 32/50\n",
      "15000/15000 [==============================] - 1s 98us/sample - loss: 0.1169 - acc: 0.9676 - val_loss: 0.2948 - val_acc: 0.8851\n",
      "Epoch 33/50\n",
      "15000/15000 [==============================] - 1s 89us/sample - loss: 0.1121 - acc: 0.9689 - val_loss: 0.2964 - val_acc: 0.8858\n",
      "Epoch 34/50\n",
      "15000/15000 [==============================] - 1s 87us/sample - loss: 0.1074 - acc: 0.9709 - val_loss: 0.2992 - val_acc: 0.8846\n",
      "Epoch 35/50\n",
      "15000/15000 [==============================] - 1s 98us/sample - loss: 0.1032 - acc: 0.9720 - val_loss: 0.3017 - val_acc: 0.8839\n",
      "Epoch 36/50\n",
      "15000/15000 [==============================] - 2s 114us/sample - loss: 0.0993 - acc: 0.9739 - val_loss: 0.3051 - val_acc: 0.8837\n",
      "Epoch 37/50\n",
      "15000/15000 [==============================] - 2s 101us/sample - loss: 0.0954 - acc: 0.9747 - val_loss: 0.3084 - val_acc: 0.8829\n",
      "Epoch 38/50\n",
      "15000/15000 [==============================] - 1s 81us/sample - loss: 0.0913 - acc: 0.9769 - val_loss: 0.3133 - val_acc: 0.8799\n",
      "Epoch 39/50\n",
      "15000/15000 [==============================] - 1s 78us/sample - loss: 0.0877 - acc: 0.9780 - val_loss: 0.3156 - val_acc: 0.8818\n",
      "Epoch 40/50\n",
      "15000/15000 [==============================] - 1s 78us/sample - loss: 0.0839 - acc: 0.9790 - val_loss: 0.3208 - val_acc: 0.8798\n",
      "Epoch 41/50\n",
      "15000/15000 [==============================] - 1s 80us/sample - loss: 0.0807 - acc: 0.9808 - val_loss: 0.3231 - val_acc: 0.8810\n",
      "Epoch 42/50\n",
      "15000/15000 [==============================] - 1s 81us/sample - loss: 0.0775 - acc: 0.9803 - val_loss: 0.3273 - val_acc: 0.8800\n",
      "Epoch 43/50\n",
      "15000/15000 [==============================] - 1s 86us/sample - loss: 0.0743 - acc: 0.9821 - val_loss: 0.3310 - val_acc: 0.8789\n",
      "Epoch 44/50\n",
      "15000/15000 [==============================] - 1s 77us/sample - loss: 0.0712 - acc: 0.9841 - val_loss: 0.3361 - val_acc: 0.8791\n",
      "Epoch 45/50\n",
      "15000/15000 [==============================] - 1s 76us/sample - loss: 0.0681 - acc: 0.9856 - val_loss: 0.3404 - val_acc: 0.8785\n",
      "Epoch 46/50\n",
      "15000/15000 [==============================] - 1s 77us/sample - loss: 0.0653 - acc: 0.9863 - val_loss: 0.3450 - val_acc: 0.8794\n",
      "Epoch 47/50\n",
      "15000/15000 [==============================] - 1s 90us/sample - loss: 0.0625 - acc: 0.9869 - val_loss: 0.3497 - val_acc: 0.8772\n",
      "Epoch 48/50\n",
      "15000/15000 [==============================] - 1s 78us/sample - loss: 0.0599 - acc: 0.9873 - val_loss: 0.3547 - val_acc: 0.8783\n",
      "Epoch 49/50\n",
      "15000/15000 [==============================] - 1s 78us/sample - loss: 0.0581 - acc: 0.9881 - val_loss: 0.3606 - val_acc: 0.8781\n",
      "Epoch 50/50\n",
      "15000/15000 [==============================] - 1s 78us/sample - loss: 0.0552 - acc: 0.9899 - val_loss: 0.3652 - val_acc: 0.8758\n",
      "Training took 66.47574710845947 seconds\n"
     ]
    }
   ],
   "source": [
    "#Making the bacthes for training data (10,000)\n",
    "x_val = train_data[:10000]\n",
    "partial_x_train = train_data[10000:]\n",
    "\n",
    "y_val = train_labels[:10000]\n",
    "partial_y_train = train_labels[10000:]\n",
    "\n",
    "#Main part - Starting the training. This is were the differnce in my CPU and Keshav's GPU was visible clearly. Detailed discussion in the report.\n",
    "start_time=time.time()\n",
    "\n",
    "# The training starts...\n",
    "history = model.fit(partial_x_train,partial_y_train,epochs=50,batch_size=512,validation_data=(x_val, y_val),verbose=1)\n",
    "print('Training took {} seconds'.format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Saving the trained model, for using in the 2nd file\n",
    "model.save(\"model.h5\")\n",
    "results = model.evaluate(test_data, test_labels, verbose=0)\n",
    "# model = tf.keras.models.load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "\n",
    "# Directly taken from the website for visualisation\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "# plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "# plt.title('Training and validation loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZwU1b3//9ebYV9EBDTKruLCDo4YA1FcgmiMGqNRxF8gxhBjNEZjvBq50UuC3kS9an5qIiZeN5TwNV8VE41Rg1viwqigghEREEeQHWRTGfh8/zjV0NNT3dMzTE3PTH+ej0c9uuvU0qd6eupTdc6pc2RmOOecc5maFToDzjnnGiYPEM4552J5gHDOORfLA4RzzrlYHiCcc87F8gDhnHMulgcIlzdJJZI2SepZl+sWkqQDJdV5W29Jx0takjb/nqSv5rNuLT7rD5J+XtvtncumeaEz4JIjaVPabFvgc2B7NP8DM5tWk/2Z2XagfV2vWwzM7OC62I+k84FzzWxU2r7Pr4t9O5fJA0QTZmY7T9DRFer5ZvZMtvUlNTezivrIm3PV8d9j4XkRUxGT9CtJf5L0kKSNwLmSjpT0iqT1kpZL+q2kFtH6zSWZpN7R/APR8iclbZT0sqQ+NV03Wn6ipAWSNkj6/yX9U9KELPnOJ48/kLRQ0jpJv03btkTSzZLWSPoAGJPj+5kkaXpG2u2S/id6f76kd6Pj+SC6us+2r3JJo6L3bSXdH+VtHnBYzOcuivY7T9IpUfpA4Dbgq1Hx3eq07/batO0viI59jaRHJe2bz3dTk+85lR9Jz0haK+kTSVekfc5/Rt/Jp5LKJO0XV5wn6aXU3zn6Pl+IPmctMElSX0mzomNZHX1vHdO27xUd46po+a2SWkd5PjRtvX0lbZHUOdvxuhhm5lMRTMAS4PiMtF8BXwDfIFwstAEOB44g3F3uDywALorWbw4Y0DuafwBYDZQCLYA/AQ/UYt29gY3AqdGyy4BtwIQsx5JPHh8DOgK9gbWpYwcuAuYB3YHOwAvh3yD2c/YHNgHt0va9EiiN5r8RrSPgWGArMChadjywJG1f5cCo6P2NwHNAJ6AXMD9j3W8D+0Z/k3OiPOwTLTsfeC4jnw8A10bvR0d5HAK0Bu4A/pHPd1PD77kjsAK4BGgF7AEMj5ZdBcwF+kbHMATYCzgw87sGXkr9naNjqwB+CJQQfo8HAccBLaPfyT+BG9OO553o+2wXrT8iWjYVmJL2OT8FHin0/2FjmwqeAZ/q6Q+dPUD8o5rtLgf+T/Q+7qT/+7R1TwHeqcW65wEvpi0TsJwsASLPPH45bfn/BS6P3r9AKGpLLTsp86SVse9XgHOi9ycCC3Ks+xfgR9H7XAFiafrfArgwfd2Y/b4DfD16X12AuBe4Lm3ZHoR6p+7VfTc1/J7/P6Asy3ofpPKbkZ5PgFhUTR7OAGZH778KfAKUxKw3AlgMKJqfA5xe1/9XTX3yIib3UfqMpEMk/TUqMvgUmAx0ybH9J2nvt5C7Yjrbuvul58PCf3R5tp3kmce8Pgv4MEd+AR4ExkbvzwF2VuxLOlnSq1ERy3rC1Xuu7ypl31x5kDRB0tyomGQ9cEie+4VwfDv3Z2afAuuAbmnr5PU3q+Z77gEszJKHHoQgURuZv8cvSZoh6eMoD/dk5GGJhQYRlZjZPwl3IyMlDQB6An+tZZ6KlgcIl9nE807CFeuBZrYH8AvCFX2SlhOucAGQJCqf0DLtTh6XE04sKdU1w/0TcLyk7oQisAejPLYBHgauJxT/7An8Pc98fJItD5L2B35HKGbpHO3332n7ra5J7jJCsVVqfx0IRVkf55GvTLm+54+AA7Jsl23Z5ihPbdPSvpSxTubx/ZrQ+m5glIcJGXnoJakkSz7uA84l3O3MMLPPs6znsvAA4TJ1ADYAm6NKvh/Uw2f+BRgm6RuSmhPKtbsmlMcZwE8kdYsqLP8j18pmtoJQDPK/wHtm9n60qBWhXHwVsF3SyYSy8nzz8HNJeyo8J3JR2rL2hJPkKkKsPJ9wB5GyAuieXlmc4SHge5IGSWpFCGAvmlnWO7Iccn3PM4Geki6S1FLSHpKGR8v+APxK0gEKhkjaixAYPyE0hiiRNJG0YJYjD5uBDZJ6EIq5Ul4G1gDXKVT8t5E0Im35/YQiqXMIwcLVkAcIl+mnwHhCpfGdhCvoREUn4bOA/yH8wx8AvEm4cqzrPP4OeBZ4G5hNuAuozoOEOoUH0/K8HrgUeIRQ0XsGIdDl4xrCncwS4EnSTl5m9hbwW+C1aJ1DgFfTtn0aeB9YISm9qCi1/d8IRUGPRNv3BMblma9MWb9nM9sAfA34FqFSfAFwdLT4BuBRwvf8KaHCuHVUdPh94OeEBgsHZhxbnGuA4YRANRP4c1oeKoCTgUMJdxNLCX+H1PIlhL/zF2b2rxoeu2NXBY5zDUZUZLAMOMPMXix0flzjJek+QsX3tYXOS2PkD8q5BkHSGEKRwWeEZpIVhKto52olqs85FRhY6Lw0Vl7E5BqKkcAiQtHDGOA0r1R0tSXpesKzGNeZ2dJC56ex8iIm55xzsfwOwjnnXKwmUwfRpUsX6927d6Gz4Zxzjcrrr7++2sxim5U3mQDRu3dvysrKCp0N55xrVCRl7U0gsSImSXdLWinpnSzLFfXauFDSW5KGpS0bL+n9aBqfVB6dc85ll2QdxD3k6EqZ0PFZ32iaSHiAieiJy2sIvUgOB66R1CnBfDrnnIuRWIAwsxcIT5hmcypwnwWvAHsq9Ft/AvC0ma01s3WEJ0dzBRrnnHMJKGQdRDcq99xYHqVlS68i6stlIkDPnlX7XNu2bRvl5eV89tlndZRll4TWrVvTvXt3WrTI1r2Qc64QChkg4nq9tBzpVRPNphL6eaG0tLTKOuXl5XTo0IHevXsTOgh1DY2ZsWbNGsrLy+nTp0/1Gzjn6k0hn4Mop3KXx90J/e9kS6+xzz77jM6dO3twaMAk0blzZ7/Lc64Wpk2D3r2hWbPwOm1adVvUTCEDxEzgO1Frpi8DG8xsOfAUMFpSp6hyenSUViseHBo+/xs5l1tcIJg2DSZOhA8/BLPwOnFi3QaJJJu5PkTofO1ghQHbv6cwmPoF0SpPEPreWQjcRRh2ETNbC/yS0BXzbGBylOacc41Gtqv7XFf9NQkEl1wCW7ZU/swtW+Dqq+vwIAo95mldTYcddphlmj9/fpW0+rR69WobPHiwDR482PbZZx/bb7/9ds5//vnnee1jwoQJ9u9//zvnOrfddps98MADdZHlgin038q56jzwgFmvXmZSeE39y8WlP/CAWdu2ZuGUHqa2bc1++MP49FzbdO5cOa26SarZcZFlbHELuyv8yb0uproIENl+AHXhmmuusRtuuKFK+o4dO2z79u1190GNlAcI11DUxQk/20m9pCQ+vVevMNUkEGSbevWq2fHmChDeWV+kPsrzUhYuXMiAAQO44IILGDZsGMuXL2fixImUlpbSv39/Jk+evHPdkSNHMmfOHCoqKthzzz258sorGTx4MEceeSQrV64EYNKkSdxyyy0717/yyisZPnw4Bx98MP/6VxhIa/PmzXzrW99i8ODBjB07ltLSUubMmVMlb9dccw2HH374zvyF3w8sWLCAY489lsGDBzNs2DCWLFkCwHXXXcfAgQMZPHgwV9fpva1zu6+mxTw1Lc6ZOjU+fc2a+Pxs3x6fvnRpmGqic2do27ZyWtu2MGVKzfaTU7bI0dim3b2DyBa9axqNs0m/g3j//fdNkr322ms7l69Zs8bMzLZt22YjR460efPmmZnZiBEj7M0337Rt27YZYE888YSZmV166aV2/fXXm5nZ1VdfbTfffPPO9a+44gozM3vsscfshBNOMDOz66+/3i688EIzM5szZ441a9bM3nzzzSr5TOVjx44ddvbZZ+/8vGHDhtnMmTPNzGzr1q22efNmmzlzpo0cOdK2bNlSadva8DsItzvqqpinrq7is021uYPo3Dl3sdTulnrgdxDVyxa9axrV83XAAQdw+OGH75x/6KGHGDZsGMOGDePdd99l/vz5VbZp06YNJ554IgCHHXbYzqv4TKeffnqVdV566SXOPvtsAAYPHkz//v1jt3322WcZPnw4gwcP5vnnn2fevHmsW7eO1atX841vfAMID7a1bduWZ555hvPOO482bdoAsNdee9X8i3AuQ9KVuNmu+q++uub/7yUl8enZru4nTsx+1T9lSvyyW28Nee7VC6TwOnUqjBsXpiVLYMeO8DqutqOPZ9FkenPdXT17hh9WXHoS2rVrt/P9+++/z6233sprr73Gnnvuybnnnhv7XEDLli13vi8pKaGioiJ2361ataqyjln1A0Nt2bKFiy66iDfeeINu3boxadKknfmIa4pqZt5E1dXatGm7Tso9e+4qGpk4cdcJPHWyT4lb1qZN/Ak/My0lVzFPtvNA586wdWvlfbZtC+PHw733Vk2/9dbwPvP4xo2DESPi01OyLavrk38+/A4iki1612l5XhaffvopHTp0YI899mD58uU89VStH/vIauTIkcyYMQOAt99+O/YOZevWrTRr1owuXbqwceNG/vznPwPQqVMnunTpwuOPPw6EBxC3bNnC6NGj+eMf/8jWrVsBWLvWWyO7quqq6ebVV9esvD+bbFf9qRNyTa7i77ij5lf3ua76k74jqCkPEJFx47L/oZM2bNgw+vXrx4ABA/j+97/PiBEj6vwzLr74Yj7++GMGDRrETTfdxIABA+jYsWOldTp37sz48eMZMGAA3/zmNzniiCN2Lps2bRo33XQTgwYNYuTIkaxatYqTTz6ZMWPGUFpaypAhQ7j55pvrPN+u4alJxW9NA0G2k31dVuLmKubJdR6ozQm/0ctWOdHYpob4HERDsm3bNtu6dauZmS1YsMB69+5t27ZtK3CudvG/VcOSq81/XTT3rE3TzbqsxE2ySXtjQ45Kaq+DKBKbNm3iuOOOo6KiAjPjzjvvpHlz//MXu5rWA2Qr5pk6tWrZfq56gGyylfXH5Su1LFd5P8Rf0afuCFw1skWOxjb5HUTj5n+rZNWkGWi2q/7U9nVxR1Dbppt+5V/38DsI54pDTe4Iatr6J1crn5KS+NZB2e4IanPVn0r3K//64wHCuUYoyUCQTepz4op5atPcE/xk39B5gHCukUm1DEoqEOSqB0id0Gvavt8DQePkzVyda6CyNSetq+cBsjUDzfXkLhRpc88i5QEiQaNGjary0Nstt9zChRdemHO79u3bA7Bs2TLOOOOMrPsuKyvLuZ9bbrmFLWlnkpNOOon169fnk3VXj2o6GExdPQ9QyC4cXCORrfa6sU0NsRXT73//e5swYUKltCOOOMJeeOGFnNu1a9eu2n0fffTRNnv27Jzr9OrVy1atWlV9RhuAQv+t6kNdtSQqVKdurmnCx4MojNWrV1uXLl3ss88+MzOzxYsXW48ePWzHjh22ceNGO/bYY23o0KE2YMAAe/TRR3dulwoQixcvtv79+5uZ2ZYtW+yss86ygQMH2re//W0bPnz4zgBxwQUX2GGHHWb9+vWzX/ziF2Zmduutt1qLFi1swIABNmrUKDOrHDBuuukm69+/v/Xv339nT7CLFy+2Qw45xM4//3zr16+ffe1rX9vZU2u6mTNn2vDhw23IkCF23HHH2SeffGJmZhs3brQJEybYgAEDbODAgfbwww+bmdmTTz5pQ4cOtUGDBtmxxx4b+10V+m9Vl+oiEGSbpOz78kDgaqNgAQIYA7xHGFb0ypjlvYBngbeA54Duacu2A3OiaWZ1n1VdgLjkErOjj67b6ZJLqv/yTzrppJ0n/+uvv94uv/xyMwtPNm/YsMHMzFatWmUHHHCA7dixw8ziA8RNN91k3/3ud83MbO7cuVZSUrIzQKS62a6oqLCjjz7a5s6da2ZV7yBS82VlZTZgwADbtGmTbdy40fr162dvvPGGLV682EpKSnZ2A37mmWfa/fffX+WY1q5duzOvd911l1122WVmZnbFFVfYJWlfytq1a23lypXWvXt3W7RoUaW8ZmoqAaKuAkGuJ4pTn+OBwNWFXAEiyTGpS4DbgROBfsBYSf0yVrsRuM/MBgGTgevTlm01syHRdEpS+Uza2LFjmT59OgDTp09n7NixQAjMP//5zxk0aBDHH388H3/8MStWrMi6nxdeeIFzzz0XgEGDBjFo0KCdy2bMmMGwYcMYOnQo8+bNi+2IL91LL73EN7/5Tdq1a0f79u05/fTTefHFFwHo06cPQ4YMAbJ3KV5eXs4JJ5zAwIEDueGGG5g3bx4AzzzzDD/60Y92rtepUydeeeUVjjrqKPr06QM0rS7B4+oOkq5ATjVn9ToCVx+SbOY6HFhoZosAJE0HTgXSz179gEuj97OAR5PKTDTgWr077bTTuOyyy3jjjTfYunUrw4YNA0Lnd6tWreL111+nRYsW9O7dO7aL73RxXWsvXryYG2+8kdmzZ9OpUycmTJhQ7X7CRUO8VFfhELoLT/XUmu7iiy/msssu45RTTuG5557j2muv3bnfzDzGpTUF2Zqa1lWT0uqeH3CuPiTZiqkb8FHafHmUlm4u8K3o/TeBDpI6R/OtJZVJekXSaXEfIGlitE7ZqlWr6jLvdaZ9+/aMGjWK8847b+fdA8CGDRvYe++9adGiBbNmzeLDuMdT0xx11FFMi9o5vvPOO7z11ltA6Cq8Xbt2dOzYkRUrVvDkk0/u3KZDhw5s3Lgxdl+PPvooW7ZsYfPmzTzyyCN89atfzfuYNmzYQLdu4U9577337kwfPXo0t9122875devWceSRR/L888+zePFioPF1CV7TpqY1HUDGWxK5hizJABF32Zh56Xo5cLSkN4GjgY+B1Cg4Pc2sFDgHuEXSAVV2ZjbVzErNrLRr1651mPW6NXbsWObOnbtzRDeAcePGUVZWRmlpKdOmTeOQQw7JuY8f/vCHbNq0iUGDBvGb3/yG4cOHA2F0uKFDh9K/f3/OO++8Sl2FT5w4kRNPPJFjjjmm0r6GDRvGhAkTGD58OEcccQTnn38+Q4cOzft4rr32Ws4880y++tWv0qVLl53pkyZNYt26dQwYMIDBgwcza9YsunbtytSpUzn99NMZPHgwZ511Vt6fU2i1aWq6fbsHAteEZKuc2N0JOBJ4Km3+KuCqHOu3B8qzLLsHOCPX5zXEVkwuf4X+W8VV+uYapzzXMq9Ado0JBRqTejbQV1IfSS2Bs4GZ6StI6iIplYergLuj9E6SWqXWAUZQue7CuTqT7U4hW6nf0qW5RyD0OwLXVCQWIMysArgIeAp4F5hhZvMkTZaUapU0CnhP0gJgHyA1wOehQJmkuYTK6/82Mw8QbrfVpOVRrqEpCzkCoXP1RZajRUtjUlpaapldT7z77rsccsghTbIVTVNiZvz73//m0EMPTfRzMlseQbjqz9XyKHN527YeCFzTIul1C/W9VTTpvphat27NmjVrcjbrdIVlZqxZs4bWrVvX6X7r4k4hdVfgdwmuWDXpO4ht27ZRXl5e7XMBrrBat25N9+7dadGiRZ3sz+8UnMtfrjuIJj0eRIsWLXY+weuanrhBc8aNy32nEDfqWa9eYVt/KM25ypp0gHBNV7YnmaH6ZxSyDYTjAcG5ypp0HYRrurLdJVx9dbgDiON1Cs7VjAcI1+DFVThnu0vwZxScqzseIFyDlu0htmydwvozCs7VHa+DcA1atqKkNm2y1yeA1yk4Vxf8DsI1GDUpSlq71u8SnEtak34OwjVMcc1TIf7ZhTZt4gfb6dUr1CE453ZP0T4H4RqebM1T27SpXVGScy45XsTk6lVNh+T0oiTnCscDhEtMTeoUskm1SvKmqc7VPw8QLhE1bZ6abUhOL0pyrnA8QLjdUtMxm6HmQ3I65wrDK6ldrdWmP6S1a+H++7N3jOcBwbmGw5u5ulrr3Tt+WM5evcJrtmXePNW5hqNgAwZJGiPpPUkLJV0Zs7yXpGclvSXpOUnd05aNl/R+NI1PMp+udmrbH5JzrnFILEBIKgFuB04E+gFjJfXLWO1G4D4zGwRMBq6Ptt0LuAY4AhgOXCOpU1J5ddWLq2vI1muq94fkXNOQ5B3EcGChmS0ysy+A6cCpGev0A56N3s9KW34C8LSZrTWzdcDTwJgE8+pyyNYi6aSTct8lePNU5xq3JANEN+CjtPnyKC3dXOBb0ftvAh0kdc5zW5eAmozl/MQTfpfgXFOWZCsmxaRl1ohfDtwmaQLwAvAxUJHntkiaCEwE6JmtvMPlLVurpGxjOS9d6r2mOteUJXkHUQ70SJvvDixLX8HMlpnZ6WY2FLg6StuQz7bRulPNrNTMSrt27VrX+S86ucZyjuMx2bmmLckAMRvoK6mPpJbA2cDM9BUkdZGUysNVwN3R+6eA0ZI6RZXTo6M0l6DqxnJO5y2SnGv6EgsQZlYBXEQ4sb8LzDCzeZImSzolWm0U8J6kBcA+wJRo27XALwlBZjYwOUpzCfKxnJ1z6fxBuSJVkzEZPBg413QV7EE51zBla7YKfqfQ0KxbB++/D59/XuicuGLkdxBFKFcXGcXQDcb69bBhQ2jKm5pKSsLrjh2wdWuYPvts1/tt28I6LVpA8+a7Xps1g40bw/5S0/r18OmnsHlz5X2k3rdoAZ06hZ5t01937IBFi+CDD8K0aFEIEBA++4AD4NBDw9SvH/TtCxUV8Z9dURF/7CUlYRCm1q3Da+p9s2a7tk/f39atsPfesN9+lad99w35btWq/v5uLhk+olwRiytKytVFRlNiBosXw9y5MGfOrqk+jrNlS2jXrvJJOPW6eXPI17p1Ydq+fdd2zZuHAL7//jB8eAgKnTuHgDF/Prz7Lvz1r9kDQGofLVvGL6uogC++qD7vHTuGqXVrePllWLkyft1WrWDPPXet37FjOM70IJp636ZN5YCYer/fftCnT7hrdQ2LB4gmLNtzDXvtFT+CW0NrtrpjRzghvvJKOEktXBhOIulX/s2ahbQtW8KJd/PmXe83btxVNNOsGRx8MIwYARdeCF27hv1nTtKuk3r6ib1ly3ByTU3btoXX7duhQ4fKJ8jUiTUfZiGf69aF9927hxNqLtu2hYCxcOGuk3n6Sbp169wn2+3bw/eSflezY0fuvG/bBp98AsuXw7JlYVq3rurdy4YNsHp11e+poiL8TTZsCMeZqVs3GDUKjjkmTOkBwwxWrAi/hXffDUVuXbvCgAHQv39Yt1mWwvIvvgj5/uyzcCfUsaMHoprwIqYmLFtRUufO4aTQkCqjt24NJ7z33w9X+a+8Aq++GopLIFxt9u+/qxgofTILJ/F27cLUtu2u9wcdBIMHh5NJZlNdV/+2bw9/07Vrd91BffABPPcczJq1606lZ89wB/XxxyEorF+/ax9t2oTfS/p8v37h99Gixa4AtmwZrFpV+fNbtAjBpWvXEDD23hu+9KWqU+qxqrhA16pVuCjo0CH8ptIDjlk4vtWrw0XY6tXhNztwYLhTaojBKVcRkweIJqxZs/irNSn3mAxJW7ECHnkE3nwzBIT334fy8sr5HjgQjjwSvvzl8Nq3b8P853J1xywEg1mzwvTmm9Cjx656l1Tdy377hbuu+fNh3jx4553wOm9e2Edmfcl++4WT+urVIQCtXBkCx8qV4beYusOojWbNoH37ECwqKkJQyFb816ULDBkSLliGDIEDDwwB8pNPKk+poJZeTJd67dULhg0L0wEHZL9zqgkPEEWqIVVGr18fgsJDD8Gzz4Yr/y5dwon/wAPDa2o6+ODwT+dcfUgV833yya6AsXJluCDJrEcpKQnBZOPGMG3atOt9SUn4TXfuXPn1iy/grbd21YG98058q7Q99oB99gl3Nc2aVb5rqagI23z44a46pA4dYOjQECy+8hU488zaHb9XUjdxcRXR48aF17jnGurqCejPPw8VwK+9Fq78UhWz6RPAX/4SOvb74otQ+XrVVTB2bCgScK7QpHBy3mOPUCSZhKOO2vW+ogLeey+0UuvSJRRp7bNPfkWgX3wR7pTefBPeeCNMd94Jr79e+wCRi99BNHKZFdFQuT4hW/CojZUr4amnQkB49dVwNbRtW1jWsWMoX968uWqx1r77wllnhaBw+OFeVORcXaqoCHU6e+9du+29iKkJS7oYaccO+Mc/QsB59NEQENq3h9LSUImYmrp3Dyd+s3BnkWpR9Pnn4a4hW4d/zrnC8iKmJiypZxo++QTuuQfuuivcCu+1F1x0EXznO6ECOdsJXwrNJFu3DmWwzrnGywNEI9ezZ/wdRG2eaSgvDw9hPf54KEqqqAht03/5Szj99Pzb9jvnmgYPEI3c7lRE79gBZWWhEvnxx0OdAoRiq5/8BM4/P7Qocs4VJw8QjVyqwrmmFdFPPAE/+lGop2jWLDxh/Otfw8knh/bmXpHsnPPeXBuRuPGiIQSDJUvCHcGSJbmDw4oVcPbZ8PWvh2aoDzwQHsx54QW44orwIJIHB+cc+B1Eo5GtXyXIr9mqGdx9N1x+edjHL38ZAkK2Tt2cc87vIBqJbONFX3119dsuWADHHhvqFAYNCk91TprkwcE5l5sHiEaiNs1ZFy2CCy4IzVLnzAlNVmfN8opn51x+Eg0QksZIek/SQklXxizvKWmWpDclvSXppCi9t6StkuZE0++TzGdjkK3Zalz622+HYqe+feF//xcmTAhdYZx/ft107uWcKw6JnS4klQC3AycC/YCxkvplrDYJmGFmQ4GzgTvSln1gZkOi6YKk8tlYTJlSta+WzOasL78Mp5wSipEeewwuuywMTHPnnaG/F+ecq4kkryeHAwvNbJGZfQFMB07NWMeAPaL3HYFlCeanURs3Lvt40Zs2wXe/G3p0/Oc/4b/+KxQ93XBD6OrYOedqI8lWTN2Aj9Lmy4EjMta5Fvi7pIuBdsDxacv6SHoT+BSYZGYvZn6ApInARICeDW04tASMG1e1xdLcuaEjvAULQoX1lVd6V9nOubqR5B1EXGv6zJ4BxwL3mFl34CTgfknNgOVAz6jo6TLgQUl7ZGyLmU01s1IzK+2aGgKqSJjBHXfAEUeEEayefRZ+9SsPDs65upNkgCgHeqTNd6dqEdL3gBkAZvYy0BroYp8BfucAABYqSURBVGafm9maKP114AMgoZ7aG5916+CMM8KT0MccE1ooHXNMoXPlnGtqkgwQs4G+kvpIakmohJ6Zsc5S4DgASYcSAsQqSV2jSm4k7Q/0BRYlmNcGJdsT0xAGBhk6FGbODHUMf/1r7fuBd865XBKrgzCzCkkXAU8BJcDdZjZP0mSgzMxmAj8F7pJ0KaH4aYKZmaSjgMmSKoDtwAVmtjapvDYkuZ6YPuIIOOGE0EXGSy+FeeecS0q1AwZFJ/lpZraufrJUO01lwKBsAwB17x662163LjRn7du33rPmnGuCdnfAoC8BsyW9AdwNPGVNZRi6Bijbk9Hl5dCqVRjdzYODc64+VFsHYWaTCHUAfwQmAO9Luk7SAQnnrSjlaq17//3hWQfnnKsPeVVSR3cMn0RTBdAJeFjSbxLMW1GKe2IaQhfdZ55Z//lxzhWvagOEpB9Leh34DfBPYKCZ/RA4DPhWwvkrOulPTKccdxw8+GDh8uScK0751EF0AU43s0pVp2a2Q9LJyWSruI0bB3vtBd/4BoweHZq0+iA+zrn6lk8R0xPAziamkjpIOgLAzN5NKmPFbOlSOOec0E33n/4EzX1YJ+dcAeQTIH4HbEqb3xylud0U90Dc9u3wne9ARQU8/DB06FDoXDrnilU+16ZKb9YaFS35Ne1uyvZA3MyZ8PzzcM89cIC3E3POFVA+dxCLoorqFtF0CUXU7UVSsg0hOmMGfPvb4S7COecKKZ8AcQHwFeBjdnXZPTHJTBWDXEOF/v73XintnCu8aouKzGwloaM9V4d69ozvUmOffaBTp/rPj3POZao2QEhqTeiWuz+ht1UAzOy8BPPV5E2ZUrkOAkJrpZtuKlyenHMuXT5FTPcT+mM6AXieMK7DxiQzVQxSD8R16xbmW7aEP/yh6ohxzjlXKPkEiAPN7D+BzWZ2L/B1YGCy2SoO55wD/fqFrjXeegvGjy90jpxzbpd8mqtui17XSxpA6I+pd2I5KiJ//CM8/TT87ndw8MGFzo1zzlWWT4CYKqkTMIkwIlx74D8TzVURWL4cLr8cRo2CH/yg0LlxzrmqcgYISc2AT6PBgl4A9q+XXBWBiy+Gzz8P9RDepNU51xDlrIMwsx3ARbXduaQxkt6TtFDSlTHLe0qaJelNSW9JOilt2VXRdu9JOqG2eWiIHn0U/vxnuPZaH/zHOddw5VNJ/bSkyyX1kLRXaqpuI0klwO3AiUA/YKykfhmrTQJmmNlQwrMWd0Tb9ovm+wNjgDui/TV669fDhRfCkCFw2WWFzo1zzmWXTx1E6nmHH6WlGdUXNw0HFprZIgBJ04FTgfkZ+9kjet8RWBa9PxWYbmafA4slLYz293Ie+W3Q/uM/YMUKePxxaNGi0Llxzrns8nmSuk8t990N+ChtPtVNR7prgb9LuhhoBxyftu0rGdt2y/wASROJuv3omWuszgKbNi30vZR6cvqkk+CwwwqbJ+ecq04+T1LHdhtnZvdVt2ncZhnzY4F7zOwmSUcC90dNafPZFjObCkwFKC0trbK8IcjstRVg1qyQ7g/FOecasnzqIA5Pm75KuOo/JY/tyoEeafPd2VWElPI9YAaAmb1M6MqjS57bNgpxvbZu3RrSnXOuIcuniOni9HlJHQndb1RnNtBXUh9CT7BnA+dkrLMUOA64R9KhhACxivC8xYOS/gfYD+gLvJbHZzY42XptzdWbq3PONQS1GfhnC+GEnZOZVUi6CHgKKAHuNrN5kiYDZWY2E/gpcJekSwlFSBOiwYnmSZpBqNCuAH5kZttrkdeC69EjPhg04CoT55wD8quDeJxd5f/NCE1WZ+SzczN7gjCmdXraL9LezwdGZNl2CjAln89pyEaOhAcfrJzWtm3ozdU55xqyfO4gbkx7XwF8aGblCeWnSVm0CB55BIYNg9Wr4aOPwp3DlCleQe2ca/jyCRBLgeVm9hmApDaSepvZkkRz1siZhT6WmjeHxx6D7t0LnSPnnKuZfFox/R9gR9r89ijN5XDfffDMM/DrX3twcM41TvkEiOZm9kVqJnrfMrksNX4rVsCll4b6B++p1TnXWOUTIFZJ2vncg6RTgdXJZanx+8lPYPNmuOsuaJbPN+yccw1QPnUQFwDTJN0WzZcDsU9XF7PM7jTOOAMOOaSweXLOud2Rz4NyHwBfltQekJn5eNQZ4rrT+OtfvTsN51zjVm0BiKTrJO1pZpvMbKOkTpJ+VR+Zayy8Ow3nXFOUTwn5iWa2PjUTjS53Uo71i453p+Gca4ryCRAlklqlZiS1AVrlWL/oZOs2w7vTcM41ZvkEiAeAZyV9T9L3gKeBe5PNVuPys59VTfPuNJxzjV21AcLMfgP8CjiU0A/T34BeCeerwZo2DXr3Ds1Xe/cO8wsXhvn99gMJevWCqVO9gto517jl25vrJ4Snqb8NLAb+nFiOGrDM1koffgjnnw/bt8P48XD33YXNn3PO1aWsAULSQYQxHMYCa4A/EZq5HlNPeWtw4lorffZZeJ00qf7z45xzScp1B/Fv4EXgG2a2ECAat6Fo5WqVtP/+9ZcP55yrD7nqIL5FKFqaJekuSccRP1Z00cjWKqlbt/rNh3PO1YesAcLMHjGzs4BDgOeAS4F9JP1O0uh6yl+DMmVKaJ2Urnnz0GOrc841Nfm0YtpsZtPM7GSgOzAHuDKfnUsaI+k9SQslVdlG0s2S5kTTAknr05ZtT1s2swbHlJhx40LrpF5pbbhuuslbKznnmiaFIaAT2LFUAiwAvkbo4G82MDYaZjRu/YuBoWZ2XjS/ycza5/t5paWlVlZWtvsZz8PixXDQQaEr79tuq35955xrqCS9bmalccuS7Ix6OLDQzBZFY0hMB07Nsf5Y4KEE81NnrrsOSkrgqqsKnRPnnEtOkgGiG/BR2nx5lFaFpF5AH+AfacmtJZVJekXSaclls2aWLw+jxZ13nldOO+eatnwflKuNuBZP2cqzzgYeNrPtaWk9zWyZpP2Bf0h6O+p6fNcHSBOBiQA966njo9/+FrZtg8suq5ePc865gknyDqIc6JE23x1YlmXds8koXjKzZdHrIkIrqqGZG5nZVDMrNbPSrl271kWec9q4EX73Ozj9dDjwwMQ/zjnnCirJADEb6Cupj6SWhCBQpTWSpIOBTsDLaWmdUj3ISuoCjABiK7fr0x/+ABs2xHfO55xzTU1iRUxmViHpIuApoAS428zmSZoMlJlZKliMBaZb5eZUhwJ3StpBCGL/na31U33Ztg1uvhmOOgqOOKKQOXHOufqRZB0EZvYE8ERG2i8y5q+N2e5fwMAk81ZTM2bARx/BHXcUOifOOVc/kixiajLM4IYb4NBD4SQfS885VyQSvYNoKp55BubOhT/+MYz74JxzxcBPd3m44QbYd1/vUsM5V1w8QFRjzhx4+mn48Y+hlY/E7ZwrIh4gqnHjjdC+PVxwQaFz4pxz9csDRA5Ll8L06fD978OeexY6N845V788QORwyy3h9Sc/KWw+nHOuEDxAZHHffXDrrbB9e3g4btq0QufIOefqlweIGNOmwcSJsGNHmP/wwzDvQcI5V0w8QMS4+mr4/PPKaVu2hHTnnCsWHiBiLF1as3TnnGuKPEDEyDYQUD0NOeGccw2CB4gYJ59cNa1tW5gypf7z4pxzheIBIsaGDbDHHuGOQYJevWDqVO9qwzlXXLyzvgzbt8NTT8Fpp8G99xY6N845Vzh+B5Fh9mxYuxZOPLHQOXHOucLyAJHhySdDl96jRxc6J845V1geIDL87W9hSNG99ip0TpxzrrASDRCSxkh6T9JCSVfGLL9Z0pxoWiBpfdqy8ZLej6bxSeYzZdWqUMTkxUvOOZdgJbWkEuB24GtAOTBb0kwzm59ax8wuTVv/YmBo9H4v4BqgFDDg9WjbdUnlF+Dvfw/Di44Zk+SnOOdc45DkHcRwYKGZLTKzL4DpwKk51h8LPBS9PwF42szWRkHhaSDx0/aTT0LXrnDYYUl/knPONXxJBohuwEdp8+VRWhWSegF9gH/UZFtJEyWVSSpbtWrVbmV2x47QvPWEE3zcaeecg2QDhGLSLMu6ZwMPm9n2mmxrZlPNrNTMSrt27VrLbAZlZbB6tdc/OOdcSpIBohzokTbfHViWZd2z2VW8VNNt68Tf/haemvbmrc45FyQZIGYDfSX1kdSSEARmZq4k6WCgE/ByWvJTwGhJnSR1AkZHaYl58kk4/HDo0iXJT3HOucYjsQBhZhXARYQT+7vADDObJ2mypFPSVh0LTDczS9t2LfBLQpCZDUyO0hKxZg28+qoXLznnXLpE+2IysyeAJzLSfpExf22Wbe8G7k4sc2lSzVs9QDjn3C7eXodQvNS5M5SWFjonzjnXcBR9gEhv3lpSUujcOOdcw1H0AeKjj0IX31685JxzlRX9eBC9esGKFSFIOOec26XoAwSEoiUvXnLOucqKvojJOedcPA8QzjnnYnmAcM45F8sDhHPOuVgeIJxzzsXyAOGccy6WBwjnnHOxPEA455yL5QHCOedcLA8QzjnnYnmAcM45F8sDhHPOuViJBghJYyS9J2mhpCuzrPNtSfMlzZP0YFr6dklzoqnKWNbOOeeSlVhvrpJKgNuBrwHlwGxJM81sfto6fYGrgBFmtk7S3mm72GpmQ5LKn3POudySvIMYDiw0s0Vm9gUwHTg1Y53vA7eb2ToAM1uZYH6cc87VQJIBohvwUdp8eZSW7iDgIEn/lPSKpDFpy1pLKovST4v7AEkTo3XKVq1aVbe5d865IpfkgEGKSbOYz+8LjAK6Ay9KGmBm64GeZrZM0v7APyS9bWYfVNqZ2VRgKkBpaWnmvp1zzu2GJO8gyoEeafPdgWUx6zxmZtvMbDHwHiFgYGbLotdFwHPA0ATz6pxzLkOSAWI20FdSH0ktgbOBzNZIjwLHAEjqQihyWiSpk6RWaekjgPk455yrN4kVMZlZhaSLgKeAEuBuM5snaTJQZmYzo2WjJc0HtgM/M7M1kr4C3ClpByGI/Xd66yfnnHPJk1nTKLovLS21srKyQmfDOecaFUmvm1lp3DJ/kto551wsDxDOOedieYBwzjkXywOEc865WB4gnHPOxfIA4ZxzLpYHCOecc7E8QDjnnIvlAcI551wsDxDOOediFX2AmDYNeveGZs3C67Rphc6Rc841DEmOB9HgTZsGEyfCli1h/sMPwzzAuHGFy5dzzjUERX0HcfXVu4JDypYtId0554pdUQeIpUtrlu6cc8WkqANEz541S3fOuWJS1AFiyhRo27ZyWtu2Id0554pdUQeIceNg6lTo1Quk8Dp1qldQO+ccJBwgJI2R9J6khZKuzLLOtyXNlzRP0oNp6eMlvR9N45PK47hxsGQJ7NgRXj04OOdckFgzV0klwO3A14ByYLakmeljS0vqC1wFjDCzdZL2jtL3Aq4BSgEDXo+2XZdUfp1zzlWW5B3EcGChmS0ysy+A6cCpGet8H7g9deI3s5VR+gnA02a2Nlr2NDAmwbw655zLkGSA6AZ8lDZfHqWlOwg4SNI/Jb0iaUwNtkXSREllkspWrVpVh1l3zjmXZIBQTJplzDcH+gKjgLHAHyTtmee2mNlUMys1s9KuXbvuZnadc86lSzJAlAM90ua7A8ti1nnMzLaZ2WLgPULAyGdb55xzCZJZlQvzutmx1BxYABwHfAzMBs4xs3lp64wBxprZeEldgDeBIUQV08CwaNU3gMPMbG2Oz1sFfFhNtroAq2t3RI1esR67H3dx8eOuuV5mFlsEk1grJjOrkHQR8BRQAtxtZvMkTQbKzGxmtGy0pPnAduBnZrYGQNIvCUEFYHKu4BB9XrVlTJLKzKy09kfVeBXrsftxFxc/7jreb1J3EA1Rsf54oHiP3Y+7uPhx162ifpLaOedcdsUWIKYWOgMFVKzH7sddXPy461BRFTE555zLX7HdQTjnnMuTBwjnnHOxiiZA5NOzbFMg6W5JKyW9k5a2l6Sno55xn5bUqZB5TIKkHpJmSXo36hn4kii9SR+7pNaSXpM0Nzru/4rS+0h6NTruP0lqWei8JkFSiaQ3Jf0lmi+W414i6W1JcySVRWl1/lsvigCR1rPsiUA/YKykfoXNVWLuoWrHhlcCz5pZX+DZaL6pqQB+amaHAl8GfhT9jZv6sX8OHGtmgwkPmY6R9GXg18DN0XGvA75XwDwm6RLg3bT5YjlugGPMbEha89Y6/60XRYAgv55lmwQzewHIfKjwVODe6P29wGn1mql6YGbLzeyN6P1GwkmjG0382C3YFM22iCYDjgUejtKb3HEDSOoOfB34QzQviuC4c6jz33qxBIi8eodtwvYxs+UQTqTA3gXOT6Ik9QaGAq9SBMceFbPMAVYSusb/AFhvZhXRKk31934LcAWwI5rvTHEcN4SLgL9Lel3SxCitzn/riXW10cDk1Tusa/wktQf+DPzEzD4NF5VNm5ltB4ZEPSE/Ahwat1r95ipZkk4GVprZ65JGpZJjVm1Sx51mhJktiwZZe1rSv5P4kGK5gyj23mFXSNoXIHpdWc36jZKkFoTgMM3M/m+UXBTHDmBm64HnCHUwe0YdZkLT/L2PAE6RtIRQZHws4Y6iqR83AGa2LHpdSbgoGE4Cv/ViCRCzgb5RC4eWwNnAzALnqT7NBFLjeo8HHitgXhIRlT//EXjXzP4nbVGTPnZJXaM7ByS1AY4n1L/MAs6IVmtyx21mV5lZdzPrTfh//oeZjaOJHzeApHaSOqTeA6OBd0jgt140T1JLOolwhZHqWXZKgbOUCEkPEQZg6gKsIIzt/SgwA+gJLAXOrK533MZG0kjgReBtdpVJ/5xQD9Fkj13SIEKFZAnhgm+GmU2WtD/hynovQjf655rZ54XLaXKiIqbLzezkYjju6BgfiWabAw+a2RRJnanj33rRBAjnnHM1UyxFTM4552rIA4RzzrlYHiCcc87F8gDhnHMulgcI55xzsTxAOFcNSdujXjNTU511+Cepd3rPu841JMXS1YZzu2OrmQ0pdCacq29+B+FcLUV98v86Go/hNUkHRum9JD0r6a3otWeUvo+kR6KxG+ZK+kq0qxJJd0XjOfw9eiIaST+WND/az/QCHaYrYh4gnKtem4wiprPSln1qZsOB2whP6hO9v8/MBgHTgN9G6b8Fno/GbhgGzIvS+wK3m1l/YD3wrSj9SmBotJ8Lkjo457LxJ6mdq4akTWbWPiZ9CWGwnkVRR4GfmFlnSauBfc1sW5S+3My6SFoFdE/v+iHqmvzpaJAXJP0H0MLMfiXpb8AmQlcpj6aN++BcvfA7COd2j2V5n22dOOl9BW1nV93g1wkjIR4GvJ7WS6lz9cIDhHO756y015ej9/8i9DAKMA54KXr/LPBD2DnIzx7ZdiqpGdDDzGYRBsXZE6hyF+NckvyKxLnqtYlGbEv5m5mlmrq2kvQq4WJrbJT2Y+BuST8DVgHfjdIvAaZK+h7hTuGHwPIsn1kCPCCpI2EgnJuj8R6cqzdeB+FcLUV1EKVmtrrQeXEuCV7E5JxzLpbfQTjnnIvldxDOOedieYBwzjkXywOEc865WB4gnHPOxfIA4ZxzLtb/A5FT2HkO/JBiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Graph plotted for 50 EPOCHS.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,  591,  202, ...,    0,    0,    0],\n",
       "       [   6,  176,    7, ...,  125,    4, 3077],\n",
       "       [  57, 4893,    5, ...,    9,   57,  975],\n",
       "       ...,\n",
       "       [   1,   13, 1408, ...,    0,    0,    0],\n",
       "       [   1,   11,  119, ...,    0,    0,    0],\n",
       "       [   1,    6,   52, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "(25000, 256)\n",
      "(256,)\n",
      "(256,)\n",
      "(256,)\n"
     ]
    }
   ],
   "source": [
    "print(type(test_data))\n",
    "for i in test_data[:3]:\n",
    "    print(type(i))\n",
    "print()\n",
    "print(test_data.shape)\n",
    "for i in test_data[:3]:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(test_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 256)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03301674],\n",
       "       [0.99991   ],\n",
       "       [0.6138225 ],\n",
       "       [0.847412  ],\n",
       "       [0.9985951 ],\n",
       "       [0.98039013],\n",
       "       [0.9422918 ],\n",
       "       [0.00419185],\n",
       "       [0.97596675],\n",
       "       [0.999977  ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"pagal\"\n",
    "test = test.lower().split(\" \")\n",
    "data = []\n",
    "for i in range(len(test)):\n",
    "    t = word_index[test[i]]\n",
    "    data.append(t)\n",
    "length = len(test) \n",
    "while length<256:\n",
    "    data.append(0)\n",
    "    length+=1\n",
    "data = np.array(data)\n",
    "data = data.reshape(1,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56990,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'movie', 'is', 'bad']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index[\"bad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,  591,  202, ...,    0,    0,    0],\n",
       "       [   6,  176,    7, ...,  125,    4, 3077],\n",
       "       [  57, 4893,    5, ...,    9,   57,  975],\n",
       "       ...,\n",
       "       [   1,   13, 1408, ...,    0,    0,    0],\n",
       "       [   1,   11,  119, ...,    0,    0,    0],\n",
       "       [   1,    6,   52, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.threading.set_inter_op_parallelism_threads(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
